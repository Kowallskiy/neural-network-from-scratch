{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor"
      ],
      "metadata": {
        "id": "yBEWtYPRJfjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = datasets.FashionMNIST(\n",
        "    train=True,\n",
        "    transform=ToTensor(),\n",
        "    download=True,\n",
        "    root='data'\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root='data',\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        "    train=False\n",
        ")"
      ],
      "metadata": {
        "id": "Xrr62g5MKgu-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78f9185d-1e74-4121-c34a-129b93423246"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:01<00:00, 18249084.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 287909.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 5550960.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 11703131.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "ZsJ7V8SbLeRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = (\n",
        "    'cuda' if torch.cuda.is_available() else 'cpu'\n",
        ")\n",
        "\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26oyVEheMFgM",
        "outputId": "2a2c78b3-87c2-4a2b-c659-a989c198feb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.linear_relu_stack = nn.Sequential(\n",
        "        nn.Linear(28*28, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 10)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.flatten(x)\n",
        "    logits = self.linear_relu_stack(x)\n",
        "    return logits"
      ],
      "metadata": {
        "id": "JNOac4i5MWk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8fg8sKP9NqI",
        "outputId": "9d480d6d-d010-4224-ff62-734f147233e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "dJFbbAVU9eQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "  model.train()\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    pred = model(X)\n",
        "    loss = loss_fn(pred, y)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      loss, current = loss.item(), (batch + 1) * len(X)\n",
        "      print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")"
      ],
      "metadata": {
        "id": "BL8J2oS8-aw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  model.eval()\n",
        "\n",
        "  test_loss, correct = 0, 0\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      pred = model(X)\n",
        "      test_loss += loss_fn(pred, y).item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "  test_loss /= num_batches\n",
        "  correct /= size\n",
        "  print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "u0FUL_yfCBjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "for t in range(epochs):\n",
        "  print(f\"Epoch: {t+1}\\n------------------------\")\n",
        "  train(train_dataloader, model, loss_fn, optimizer)\n",
        "  test(test_dataloader, model, loss_fn)\n",
        "print(\"Done\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jsq6LvD5FQyx",
        "outputId": "237948f2-85fc-418c-abd0-2c13f55e5a0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1\n",
            "------------------------\n",
            "loss: 2.307316 [   64/60000]\n",
            "loss: 2.294809 [ 6464/60000]\n",
            "loss: 2.268579 [12864/60000]\n",
            "loss: 2.262986 [19264/60000]\n",
            "loss: 2.257206 [25664/60000]\n",
            "loss: 2.228195 [32064/60000]\n",
            "loss: 2.237793 [38464/60000]\n",
            "loss: 2.206419 [44864/60000]\n",
            "loss: 2.191752 [51264/60000]\n",
            "loss: 2.166111 [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 44.5%, Avg loss: 2.164060 \n",
            "\n",
            "Epoch: 2\n",
            "------------------------\n",
            "loss: 2.181288 [   64/60000]\n",
            "loss: 2.171366 [ 6464/60000]\n",
            "loss: 2.108002 [12864/60000]\n",
            "loss: 2.118260 [19264/60000]\n",
            "loss: 2.084996 [25664/60000]\n",
            "loss: 2.022558 [32064/60000]\n",
            "loss: 2.052957 [38464/60000]\n",
            "loss: 1.976232 [44864/60000]\n",
            "loss: 1.966843 [51264/60000]\n",
            "loss: 1.902168 [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 54.2%, Avg loss: 1.904265 \n",
            "\n",
            "Epoch: 3\n",
            "------------------------\n",
            "loss: 1.943655 [   64/60000]\n",
            "loss: 1.918300 [ 6464/60000]\n",
            "loss: 1.795068 [12864/60000]\n",
            "loss: 1.827301 [19264/60000]\n",
            "loss: 1.740190 [25664/60000]\n",
            "loss: 1.678415 [32064/60000]\n",
            "loss: 1.703632 [38464/60000]\n",
            "loss: 1.601006 [44864/60000]\n",
            "loss: 1.615013 [51264/60000]\n",
            "loss: 1.518459 [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 60.2%, Avg loss: 1.537951 \n",
            "\n",
            "Epoch: 4\n",
            "------------------------\n",
            "loss: 1.604029 [   64/60000]\n",
            "loss: 1.576222 [ 6464/60000]\n",
            "loss: 1.420599 [12864/60000]\n",
            "loss: 1.489450 [19264/60000]\n",
            "loss: 1.386708 [25664/60000]\n",
            "loss: 1.363451 [32064/60000]\n",
            "loss: 1.384554 [38464/60000]\n",
            "loss: 1.302973 [44864/60000]\n",
            "loss: 1.330247 [51264/60000]\n",
            "loss: 1.240599 [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 63.5%, Avg loss: 1.268661 \n",
            "\n",
            "Epoch: 5\n",
            "------------------------\n",
            "loss: 1.340797 [   64/60000]\n",
            "loss: 1.330694 [ 6464/60000]\n",
            "loss: 1.163185 [12864/60000]\n",
            "loss: 1.265748 [19264/60000]\n",
            "loss: 1.149979 [25664/60000]\n",
            "loss: 1.159261 [32064/60000]\n",
            "loss: 1.187432 [38464/60000]\n",
            "loss: 1.119005 [44864/60000]\n",
            "loss: 1.150240 [51264/60000]\n",
            "loss: 1.077916 [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 64.6%, Avg loss: 1.099637 \n",
            "\n",
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensors"
      ],
      "metadata": {
        "id": "F6bP2_oVOZp2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "lPZ62RivObPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [[1, 2], [3, 4]]\n",
        "x_data = torch.tensor(data)"
      ],
      "metadata": {
        "id": "XjS6LTC-Oxdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np_array = np.array(data)\n",
        "x_np = torch.from_numpy(np_array)"
      ],
      "metadata": {
        "id": "xuL6kAUFO9zu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_ones = torch.ones_like(x_data)\n",
        "print(f\"Tensor: \\n {x_ones} \\n\")\n",
        "\n",
        "x_rand = torch.rand_like(x_data, dtype=torch.float)\n",
        "print(f\"Tensor: \\n {x_rand} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3p8xJwQLPQlM",
        "outputId": "02431c66-4db7-4da1-de85-95c98ca51e6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor: \n",
            " tensor([[1, 1],\n",
            "        [1, 1]]) \n",
            "\n",
            "Tensor: \n",
            " tensor([[0.5923, 0.0012],\n",
            "        [0.4990, 0.2615]]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shape = (5, 2, 4)\n",
        "\n",
        "tensor_one = torch.ones(shape)\n",
        "tensor_rand = torch.rand(shape)\n",
        "tensor_zero = torch.zeros(shape)\n",
        "\n",
        "print(f\"Tensor: \\n {tensor_one} \\n\")\n",
        "print(f\"Tensor: \\n {tensor_rand} \\n\")\n",
        "print(f\"Tensor: \\n {tensor_zero} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1ksp3dAQbKo",
        "outputId": "1f166fc4-66f3-4483-ee18-0185dd6fd173"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor: \n",
            " tensor([[[1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.]],\n",
            "\n",
            "        [[1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.]],\n",
            "\n",
            "        [[1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.]],\n",
            "\n",
            "        [[1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.]],\n",
            "\n",
            "        [[1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.]]]) \n",
            "\n",
            "Tensor: \n",
            " tensor([[[0.7677, 0.5900, 0.5250, 0.8857],\n",
            "         [0.7880, 0.3378, 0.8123, 0.5675]],\n",
            "\n",
            "        [[0.5431, 0.6184, 0.7395, 0.0870],\n",
            "         [0.1053, 0.1169, 0.9323, 0.4232]],\n",
            "\n",
            "        [[0.5179, 0.7287, 0.5106, 0.7562],\n",
            "         [0.7919, 0.4161, 0.5821, 0.3447]],\n",
            "\n",
            "        [[0.0054, 0.4446, 0.2166, 0.5242],\n",
            "         [0.9331, 0.8972, 0.2350, 0.3296]],\n",
            "\n",
            "        [[0.3759, 0.8352, 0.5668, 0.4259],\n",
            "         [0.4062, 0.3368, 0.9110, 0.6016]]]) \n",
            "\n",
            "Tensor: \n",
            " tensor([[[0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.]]]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.rand(3, 4)\n",
        "\n",
        "print(f\"Tensor's datatype: {tensor.dtype}\")\n",
        "print(f\"Tensor's shape: {tensor.shape}\")\n",
        "print(f\"Tensor's device: {tensor.device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hY7TJqTVRP2K",
        "outputId": "c676d74e-7e41-4313-c07a-92039ef77b30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor's datatype: torch.float32\n",
            "Tensor's shape: torch.Size([3, 4])\n",
            "Tensor's device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  tensor = tensor.to('cuda')"
      ],
      "metadata": {
        "id": "9A_fuvqURrxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.ones(4, 4)\n",
        "print(f\"The first row: {tensor[0]}\")\n",
        "print(f\"The second column: {tensor[:, 1]}\")\n",
        "print(f\"The last column: {tensor[..., -1]}\")\n",
        "tensor[:, 2] = 69\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-sXCpkxSHTw",
        "outputId": "3d98d7e0-1ec2-49a7-c1f3-730eac13bb7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The first row: tensor([1., 1., 1., 1.])\n",
            "The second column: tensor([1., 1., 1., 1.])\n",
            "The last column: tensor([1., 1., 1., 1.])\n",
            "tensor([[ 1.,  1., 69.,  1.],\n",
            "        [ 1.,  1., 69.,  1.],\n",
            "        [ 1.,  1., 69.,  1.],\n",
            "        [ 1.,  1., 69.,  1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
        "print(t1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yomy4QNJS0f1",
        "outputId": "14d2e513-4900-464d-95dd-ff75fef9e982"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.,  1., 69.,  1.,  1.,  1., 69.,  1.,  1.,  1., 69.,  1.],\n",
            "        [ 1.,  1., 69.,  1.,  1.,  1., 69.,  1.,  1.,  1., 69.,  1.],\n",
            "        [ 1.,  1., 69.,  1.,  1.,  1., 69.,  1.,  1.,  1., 69.,  1.],\n",
            "        [ 1.,  1., 69.,  1.,  1.,  1., 69.,  1.,  1.,  1., 69.,  1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y1 = tensor.mm(tensor.T)\n",
        "y2 = torch.rand_like(y1)\n",
        "res = torch.matmul(tensor, tensor.T, out=y2)\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lpqos33STTMR",
        "outputId": "339ba1c1-5a59-4ebf-b51d-4afcd94808af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[4764., 4764., 4764., 4764.],\n",
            "        [4764., 4764., 4764., 4764.],\n",
            "        [4764., 4764., 4764., 4764.],\n",
            "        [4764., 4764., 4764., 4764.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agg = tensor.sum()\n",
        "agg_item = agg.item()\n",
        "print(f\"The sum: {agg_item} \\nThe datatype: {type(agg_item)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jJQdRBkWs0Z",
        "outputId": "b605e5d2-bfce-49ff-b706-0d17524c9452"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sum: 288.0 \n",
            "The datatype: <class 'float'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor)\n",
        "tensor.add_(3)\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXsle3oeXRTy",
        "outputId": "689e2e3f-484e-40e2-8890-688ed55dc58f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.,  1., 69.,  1.],\n",
            "        [ 1.,  1., 69.,  1.],\n",
            "        [ 1.,  1., 69.,  1.],\n",
            "        [ 1.,  1., 69.,  1.]])\n",
            "tensor([[ 4.,  4., 72.,  4.],\n",
            "        [ 4.,  4., 72.,  4.],\n",
            "        [ 4.,  4., 72.,  4.],\n",
            "        [ 4.,  4., 72.,  4.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datasets and DataLoaders"
      ],
      "metadata": {
        "id": "3IYwuBD3G9B8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "0cIGVsBCXVIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = datasets.FashionMNIST(\n",
        "    root='data',\n",
        "    download=True,\n",
        "    train=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root='data',\n",
        "    download=True,\n",
        "    train=False,\n",
        "    transform=ToTensor()\n",
        ")"
      ],
      "metadata": {
        "id": "13f02jpFH3o8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from torchvision.io import read_image"
      ],
      "metadata": {
        "id": "B8xLW8mdIYV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomImageDataset:\n",
        "  def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
        "    self.img_labels = pd.read_csv(annotations_file)\n",
        "    self.img_dir = img_dir\n",
        "    self.transform = transform\n",
        "    self.target_transform = target_transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.img_labels)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "    image = read_image(img_path)\n",
        "    label = self.img_labels.iloc[idx, 1]\n",
        "    if self.transform:\n",
        "      image = self.transform(image)\n",
        "    if self.target_transform:\n",
        "      label = self.target_transform(label)\n",
        "    return image, label"
      ],
      "metadata": {
        "id": "pS6jxJDJKGbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "QIC6xk88Vb1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "zOh4gYwsVho-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "print(f\"Features batch shape: {train_features.shape()}\")\n",
        "print(f\"Labels batch shape: {train_labels.shape()}\")\n",
        "img = train_features[0].squeeze()\n",
        "labels = train_labels[0]\n",
        "plt.imshow(img, cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "j3a68LTHV2B5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transforms"
      ],
      "metadata": {
        "id": "5DOuT8uFXxiG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms import Lambda"
      ],
      "metadata": {
        "id": "JvMlVm_CXlz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        "    target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
        ")"
      ],
      "metadata": {
        "id": "qUIwifuPZz3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Networks"
      ],
      "metadata": {
        "id": "fGZnHV_rcGJx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "id": "8Q5OzWaKcH6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEWNjdwichLs",
        "outputId": "d15d536e-1a11-4c7e-893a-d6e457f0d87e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.linear_relu_stack = nn.Sequential(\n",
        "        nn.Linear(28*28, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 10)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.flatten(x)\n",
        "    logits = self.linear_relu_stack(x)\n",
        "    return logits"
      ],
      "metadata": {
        "id": "aP6WWeR3dHvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUfc4IfugZv_",
        "outputId": "0ed2865e-8fe0-4279-acd4-1dbff9292d38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.rand(1, 28, 28, device=device)\n",
        "logits = model(X)\n",
        "pred_probab = nn.Softmax(dim=1)(logits)\n",
        "y_pred = pred_probab.argmax(1)\n",
        "print(f\"Predicted class: {y_pred}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bcInAEDgeBf",
        "outputId": "333a74e0-57e0-4552-cd96-b7e4c6c94398"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: tensor([0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_image = torch.rand(3, 28, 28)\n"
      ],
      "metadata": {
        "id": "UD-9yQsInw8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimization"
      ],
      "metadata": {
        "id": "ZFcm3qzTWR9t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=64)\n",
        "test_dataloader = DataLoader(test_data, batch_size=64)\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omUf_vVnWThM",
        "outputId": "e36bd292-b880-4ac9-8e66-8368c6d6dde1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:01<00:00, 16342210.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 336085.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 6041928.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 8766657.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "gZIZ2_xWWXLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "2QDP_pxZdIWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "  model.train()\n",
        "\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    pred = model(X)\n",
        "    loss = loss_fn(pred, y)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      loss, current = loss.item(), (batch + 1) * len(X)\n",
        "      print(f\"Loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "  model.eval()\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  test_loss, correct = 0, 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      pred = model(X)\n",
        "      test_loss += loss_fn(pred, y).item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "  test_loss /= num_batches\n",
        "  correct /= size\n",
        "\n",
        "  print(f\"Test Error: \\nAccuracy: {100*correct:>0.1f}%, Avg loss: {test_loss:>8f}\\n\")"
      ],
      "metadata": {
        "id": "RiOCx2rcdWIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "for t in range(epochs):\n",
        "  print(f\"Epoch: {t+1}\\n-----------------------------\")\n",
        "  train_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "  test_loop(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZm1dxovsWzo",
        "outputId": "b51602c5-0820-4d37-a72b-5feeaa0be86d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1\n",
            "-----------------------------\n",
            "Loss: 2.302909 [   64/60000]\n",
            "Loss: 2.295131 [ 6464/60000]\n",
            "Loss: 2.272087 [12864/60000]\n",
            "Loss: 2.267808 [19264/60000]\n",
            "Loss: 2.255293 [25664/60000]\n",
            "Loss: 2.216960 [32064/60000]\n",
            "Loss: 2.232564 [38464/60000]\n",
            "Loss: 2.192146 [44864/60000]\n",
            "Loss: 2.185643 [51264/60000]\n",
            "Loss: 2.161453 [57664/60000]\n",
            "Test Error: \n",
            "Accuracy: 41.6%, Avg loss: 2.154375\n",
            "\n",
            "Epoch: 2\n",
            "-----------------------------\n",
            "Loss: 2.163744 [   64/60000]\n",
            "Loss: 2.159865 [ 6464/60000]\n",
            "Loss: 2.096439 [12864/60000]\n",
            "Loss: 2.114757 [19264/60000]\n",
            "Loss: 2.073297 [25664/60000]\n",
            "Loss: 2.001825 [32064/60000]\n",
            "Loss: 2.037916 [38464/60000]\n",
            "Loss: 1.950110 [44864/60000]\n",
            "Loss: 1.951133 [51264/60000]\n",
            "Loss: 1.890529 [57664/60000]\n",
            "Test Error: \n",
            "Accuracy: 55.4%, Avg loss: 1.882379\n",
            "\n",
            "Epoch: 3\n",
            "-----------------------------\n",
            "Loss: 1.912804 [   64/60000]\n",
            "Loss: 1.891150 [ 6464/60000]\n",
            "Loss: 1.761508 [12864/60000]\n",
            "Loss: 1.809571 [19264/60000]\n",
            "Loss: 1.705895 [25664/60000]\n",
            "Loss: 1.647617 [32064/60000]\n",
            "Loss: 1.678047 [38464/60000]\n",
            "Loss: 1.564391 [44864/60000]\n",
            "Loss: 1.589443 [51264/60000]\n",
            "Loss: 1.501285 [57664/60000]\n",
            "Test Error: \n",
            "Accuracy: 60.8%, Avg loss: 1.507170\n",
            "\n",
            "Epoch: 4\n",
            "-----------------------------\n",
            "Loss: 1.570679 [   64/60000]\n",
            "Loss: 1.545190 [ 6464/60000]\n",
            "Loss: 1.383494 [12864/60000]\n",
            "Loss: 1.467523 [19264/60000]\n",
            "Loss: 1.354635 [25664/60000]\n",
            "Loss: 1.343712 [32064/60000]\n",
            "Loss: 1.367013 [38464/60000]\n",
            "Loss: 1.276694 [44864/60000]\n",
            "Loss: 1.315582 [51264/60000]\n",
            "Loss: 1.235593 [57664/60000]\n",
            "Test Error: \n",
            "Accuracy: 63.5%, Avg loss: 1.246570\n",
            "\n",
            "Epoch: 5\n",
            "-----------------------------\n",
            "Loss: 1.321730 [   64/60000]\n",
            "Loss: 1.310936 [ 6464/60000]\n",
            "Loss: 1.135149 [12864/60000]\n",
            "Loss: 1.250334 [19264/60000]\n",
            "Loss: 1.132831 [25664/60000]\n",
            "Loss: 1.151423 [32064/60000]\n",
            "Loss: 1.180179 [38464/60000]\n",
            "Loss: 1.101304 [44864/60000]\n",
            "Loss: 1.145489 [51264/60000]\n",
            "Loss: 1.079851 [57664/60000]\n",
            "Test Error: \n",
            "Accuracy: 64.8%, Avg loss: 1.085575\n",
            "\n",
            "Epoch: 6\n",
            "-----------------------------\n",
            "Loss: 1.154875 [   64/60000]\n",
            "Loss: 1.163529 [ 6464/60000]\n",
            "Loss: 0.971348 [12864/60000]\n",
            "Loss: 1.113499 [19264/60000]\n",
            "Loss: 0.993145 [25664/60000]\n",
            "Loss: 1.019875 [32064/60000]\n",
            "Loss: 1.062259 [38464/60000]\n",
            "Loss: 0.988537 [44864/60000]\n",
            "Loss: 1.032558 [51264/60000]\n",
            "Loss: 0.980631 [57664/60000]\n",
            "Test Error: \n",
            "Accuracy: 65.7%, Avg loss: 0.980190\n",
            "\n",
            "Epoch: 7\n",
            "-----------------------------\n",
            "Loss: 1.037092 [   64/60000]\n",
            "Loss: 1.067076 [ 6464/60000]\n",
            "Loss: 0.858230 [12864/60000]\n",
            "Loss: 1.020979 [19264/60000]\n",
            "Loss: 0.903114 [25664/60000]\n",
            "Loss: 0.925999 [32064/60000]\n",
            "Loss: 0.983584 [38464/60000]\n",
            "Loss: 0.914902 [44864/60000]\n",
            "Loss: 0.954148 [51264/60000]\n",
            "Loss: 0.914019 [57664/60000]\n",
            "Test Error: \n",
            "Accuracy: 66.9%, Avg loss: 0.908040\n",
            "\n",
            "Epoch: 8\n",
            "-----------------------------\n",
            "Loss: 0.950257 [   64/60000]\n",
            "Loss: 1.000016 [ 6464/60000]\n",
            "Loss: 0.777341 [12864/60000]\n",
            "Loss: 0.955413 [19264/60000]\n",
            "Loss: 0.842164 [25664/60000]\n",
            "Loss: 0.857010 [32064/60000]\n",
            "Loss: 0.927530 [38464/60000]\n",
            "Loss: 0.866173 [44864/60000]\n",
            "Loss: 0.897775 [51264/60000]\n",
            "Loss: 0.866426 [57664/60000]\n",
            "Test Error: \n",
            "Accuracy: 68.1%, Avg loss: 0.856188\n",
            "\n",
            "Epoch: 9\n",
            "-----------------------------\n",
            "Loss: 0.883660 [   64/60000]\n",
            "Loss: 0.949961 [ 6464/60000]\n",
            "Loss: 0.717042 [12864/60000]\n",
            "Loss: 0.906784 [19264/60000]\n",
            "Loss: 0.798535 [25664/60000]\n",
            "Loss: 0.804822 [32064/60000]\n",
            "Loss: 0.885085 [38464/60000]\n",
            "Loss: 0.832483 [44864/60000]\n",
            "Loss: 0.855919 [51264/60000]\n",
            "Loss: 0.830479 [57664/60000]\n",
            "Test Error: \n",
            "Accuracy: 69.3%, Avg loss: 0.816971\n",
            "\n",
            "Epoch: 10\n",
            "-----------------------------\n",
            "Loss: 0.830637 [   64/60000]\n",
            "Loss: 0.910003 [ 6464/60000]\n",
            "Loss: 0.670313 [12864/60000]\n",
            "Loss: 0.869148 [19264/60000]\n",
            "Loss: 0.765238 [25664/60000]\n",
            "Loss: 0.764277 [32064/60000]\n",
            "Loss: 0.850955 [38464/60000]\n",
            "Loss: 0.807835 [44864/60000]\n",
            "Loss: 0.823689 [51264/60000]\n",
            "Loss: 0.801776 [57664/60000]\n",
            "Test Error: \n",
            "Accuracy: 70.4%, Avg loss: 0.785790\n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save"
      ],
      "metadata": {
        "id": "KpNALPftwkQ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models"
      ],
      "metadata": {
        "id": "436w9fp3wlha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.vgg16(weights=\"IMAGENET1K_V1\")\n",
        "torch.save(model.state_dict(), \"model_weights.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "as-cPOvkwp1y",
        "outputId": "97e8680b-66fe-40a4-f9d0-0f6a06f72874"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:07<00:00, 75.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load"
      ],
      "metadata": {
        "id": "lolNtWaTx_Em"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.vgg16()\n",
        "model.load_state_dict(torch.load(\"/content/model_weights.pth\"), strict=False)\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuzDuLRDxt_c",
        "outputId": "32121bdb-f40e-47be-d8d4-84f8eae05086"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zCd9SEi_zBky"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}